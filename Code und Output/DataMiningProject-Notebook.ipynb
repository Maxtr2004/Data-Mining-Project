{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Projekt\n",
    "## Wie soll der nächste Charakter aussehen?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemdefiniton\n",
    "In League of Legends beeinflussen neue Champions die Spielbalance. Doch sind bestimmte Champion-Typen unterrepräsentiert? Diese Arbeit nutzt Machine Learning, um vorherzusagen, welche Champion-Eigenschaften im aktuellen Spielgewicht fehlen.\n",
    "\n",
    "So wird sich die zentrale Frage gestellt: Welche Klassen-Rollen-Kombination ist bei sonst durchschnittlichen Werten im derzeitigen Spielökosystem am stärksten unterrepräsentiert und könnte als Grundlage für die Entwicklung eines neuen Champions dienen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import - Datenauswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import notwendiger Bibliotheken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenverarbeitung & Numerik\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "# Visualisierung\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "%matplotlib inline  \n",
    "\n",
    "# Datenaufbereitung & Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Machine Learning Modelle\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor  \n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "from xgboost import XGBClassifier, XGBRegressor \n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "# Modellbewertung\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  \n",
    "from sklearn.metrics import r2_score, mean_squared_error \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Hyperparameter-Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Explorative Datenanalyse\n",
    "#from ydata_profiling import ProfileReport  \n",
    "\n",
    "# Sonstiges\n",
    "import itertools  \n",
    "from itertools import product\n",
    "import pickle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenimport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Datensatz wurde auf der Website \"Kaggle\" gefunden, hat seinen Ursprung jedoch in\n",
    "der Analyse- und Datenplattform MetaSRC. Diese Plattform sammelt, aggregiert und analysiert Match-Daten\n",
    "um die Trends des Spiels League of Legends darzustellen.\n",
    "Die Daten werden direkt aus öffentlichen Riot Games-APIs bezogen, wodurch die Statistiken\n",
    "patch-basiert aktualisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz laden\n",
    "df = pd.read_csv('../Daten/League of Legends Champion Stats 12.1.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der nächste Datensatz entstammt auch Kaggle, hat aber seinen Ursprung in dem \"League of Legends Wiki Champion Data Module\".\n",
    "Da dieser Veröffentlichungsdaten beinhaltet, eignet sich dieser für Zeitreihenanalysen\n",
    "Der Fokus liegt allerdings auf ersterem Datensatz, dieser dient nur als Hilfe für die Zeitreihenanalyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = pd.read_csv('../Daten/200125_LoL_champion_data.csv')\n",
    "df_basic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbunden werden die Datensätze durch den gemeinsamen Schlüssel des Champion-Namens\n",
    "# Dabei wollen wir zum ersten Datensatz die Informationen bezüglich Veröffenlichungsdatum hinzufügen\n",
    "\n",
    "# Spaltennamen für Konsistenz anpassen\n",
    "df_basic.rename(columns={'apiname': 'Name'}, inplace=True)\n",
    "\n",
    "# 'date' Spalte in datetime umwandeln\n",
    "df_basic['date'] = pd.to_datetime(df_basic['date'], errors='coerce')\n",
    "\n",
    "# Füge die Veröffentlichungsdaten aus df_basic zum Haupt-Datensatz df hinzu\n",
    "df = pd.merge(df, df_basic[['Name', 'date']], on='Name', how='left')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA und Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da dies ein Machine Learning Projekt ist, ist es wichtig, dass wir in den folgenden Abschnitten einen Überblick über die Daten erhalten und die Daten entsprechend vorbereiten.\n",
    "Für die spätere Modellerstellung ist es dabei wichtig, dass Nullwerte entfernt werden, die Daten in numerische Werte umgewandelt werden und die Daten in Trainings- und Testdaten aufgeteilt werden.\n",
    "Auch Skalierung der Daten ist wichtig, um sicherzustellen, dass die Modelle korrekt trainiert werden.\n",
    "Der erste Schritt ist es, sich die Daten genauer anzuschauen, um zu sehen, welche Daten vorhanden sind und wie sie aussehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Übersicht über die Daten\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beschreibung der numerischen Spalten\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeitreihenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veröffentlichungsdatum extrahieren\n",
    "df['release_year'] = df['date'].dt.year\n",
    "\n",
    "# Date spalte entfernen\n",
    "df.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der veröffentlichten Champions pro Jahr berechnen\n",
    "release_counts = df['release_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veröffentlichung pro Rolle und Klasse\n",
    "role_counts = df.groupby(['release_year', 'Role']).size().unstack()\n",
    "class_counts = df.groupby(['release_year', 'Class']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl veröffentlichter Champions pro Jahr \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(release_counts.index, release_counts.values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Anzahl der veröffentlichten Champions pro Jahr\")\n",
    "plt.xticks(release_counts.index) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: In numerische Werte umwandeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umwandlung von Prozentangaben in numerische Werte\n",
    "df[\"Win %\"] = df[\"Win %\"].str.replace('%', '').astype(float)\n",
    "df[\"Role %\"] = df[\"Role %\"].str.replace('%', '').astype(float)\n",
    "df[\"Pick %\"] = df[\"Pick %\"].str.replace('%', '').astype(float)\n",
    "df[\"Ban %\"] = df[\"Ban %\"].str.replace('%', '').astype(float)\n",
    "\n",
    "\n",
    "print(df[\"Pick %\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betrachtung fehlender Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Zeilen ausgeben, in denen das 'release_year' fehlt\n",
    "missing_year_rows = df[df[\"release_year\"].isnull()]\n",
    "print(missing_year_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_year = round(df[\"release_year\"].mean())  # Aufrunden, da Jahre ganzzahlig sind\n",
    "df[\"release_year\"].fillna(mean_year, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Zeile ausgeben, in welcher ein Wert für 'Class' fehlt\n",
    "missing_names_rows = df[df[\"Class\"].isnull()]  \n",
    "print(missing_names_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Den Champion 'Lillia' anzeigen\n",
    "df[df['Name'] == 'Lillia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da ich weiss, dass Lillia Fighter ist, kann ich den Wert direkt einfügen\n",
    "df.loc[df['Name'] == 'Lillia', 'Class'] = 'Fighter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weitere EDA-Visualisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veröffentlichungen nach Rolle\n",
    "plt.figure(figsize=(12, 6))\n",
    "role_counts.plot(kind='line', marker='o', linestyle='-', figsize=(12, 6))\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Champion-Veröffentlichungen pro Rolle\")\n",
    "plt.xticks(release_counts.index)\n",
    "plt.legend(title=\"Rolle\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veröffentlichungen nach Klasse\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_counts.plot(kind='line', marker='s', linestyle='-', figsize=(12, 6))\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Champion-Veröffentlichungen pro Klasse\")\n",
    "plt.xticks(release_counts.index)\n",
    "plt.legend(title=\"Klasse\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot zur Visualisierung der Feature-Zusammenhänge\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "sns.pairplot(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight = {\"Tank\", \"Mage\", \"Fighter\"}\n",
    "purple = \"#800080\"   \n",
    "\n",
    "order = [\"Fighter\", \"Mage\", \"Assassin\", \"Marksman\", \"Tank\", \"Support\"]\n",
    "\n",
    "palette = {c: (\"grey\" if c not in highlight else purple) for c in order}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(\n",
    "    x=\"Class\",\n",
    "    y=\"Pick %\",\n",
    "    data=df,\n",
    "    order=order,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"Pickrate pro Champion-Klasse\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Winrate\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Win %'].hist(bins=20, color='grey', edgecolor='black')\n",
    "plt.grid(False)\n",
    "plt.title('Verteilung der Winrate der Champions')\n",
    "plt.xlabel('Winrate')\n",
    "plt.ylabel('Anzahl Champions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ydata Profiling Report erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bevor die Namensspalte entfernt wird, speichern wir den df in einer neuen Variable\n",
    "df_name = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für den ydata_profiling Report entfernen wir nicht float Datentypen wie 'Name'\n",
    "df_profile_report = df.drop(['Name'], axis=1)\n",
    "df_profile_report = df_profile_report.drop(['Class'], axis=1)\n",
    "df_profile_report = df_profile_report.drop(['Role'], axis=1)\n",
    "df_profile_report = df_profile_report.drop(['release_year'], axis=1)\n",
    "df_profile_report = df_profile_report.drop(['Tier'], axis=1)\n",
    "\n",
    "# Ydata Profiling Report erstellen\n",
    "#profile = ProfileReport(df_profile_report, explorative=True)\n",
    "\n",
    "# den Profile Report als HTML-Datei speichern\n",
    "#ytrain = False\n",
    "#if ytrain:\n",
    "    #profile.to_file(\"ydata_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellauswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Modell soll vorhersagen, ob und wie Championeigenschaften wie deren Rolle zu einer Unterrepräsentation beitragen. Dazu werden mehrere Machnine Learning Modelle trainiert und anschließend verglichen. Die Modelle sind: Random Forest, Logistic Regression, Support Vector Machine und XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Auswahl und Test-Train-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst wird die Zielvariable (Pick %) von den Features getrennt, und die Daten werden im Verhältnis 80:20 in Trainings- und Testsets aufgeteilt. Zudem wird die Spalte \"Name\" entfernt, da sie für das Modell nicht einfach in Kategorien oder numerische Werte umgewandelt werden kann. Auch die Variable \"Release Year\" wird entfernt, da diese keinen logischen Zusammenhang mit der Pickrate hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Spalte 'name' wird entfernt\n",
    "df.drop(columns=[\"Name\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zielvariable definieren\n",
    "X = df.drop(columns=[\"Pick %\"]) \n",
    "y = df[\"Pick %\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kombiniert eine Pipeline das Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifikation numerischer und kategorischer Features\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Preprocessing Pipeline mit OrdinalEncoder (numerische Kodierung von Kategorien)\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), categorical_features)  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelltestung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden die Modelle getestet, um zu sehen, welches Modell am besten performt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelle\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training und Evaluation der Modelle\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"R² Score\": r2, \"RMSE\": rmse}\n",
    "    print(f\"{name}: R² = {r2:.4f}, RMSE = {rmse:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestes Modell basierend auf dem höchsten R² Score ermitteln\n",
    "best_model_name = max(results, key=lambda k: results[k][\"R² Score\"])\n",
    "print(f\"Bestes Modell: {best_model_name}\")\n",
    "\n",
    "# Bestes Modell aus dem Dictionary holen\n",
    "best_model = models[best_model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Vorhersage\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, y_pred, color='purple', label=\"Vorhersagen\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linestyle='--', color='black', label=\"Ideal\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuen berechnen\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Residuenplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_pred, residuals, alpha=0.7, color=\"darkred\", edgecolor=\"black\")\n",
    "plt.axhline(y=0, linestyle='--', color='black')\n",
    "plt.title(\"Residuenanalyse\")\n",
    "plt.xlabel(\"Vorhergesagte Pickrate\")\n",
    "plt.ylabel(\"\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Modells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter-Tuning mit GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gitter für die Hyperparameter\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [None, 10, 20]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"model__max_depth\": [3, 5]\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        \"model__hidden_layer_sizes\": [(64, 32), (128, 64)],\n",
    "        \"model__alpha\": [0.0001, 0.001]\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    if name in param_grids:\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[name], cv=3, scoring='r2', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        print(f\"Beste Parameter für {name}: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        best_model = pipeline\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"R² Score\": r2, \"RMSE\": rmse}\n",
    "    print(f\"{name}: R² = {r2:.4f}, RMSE = {rmse:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwende bestes Modell aus GridSearch falls vorhanden\n",
    "best_xgb = XGBRegressor(\n",
    "    n_estimators=200,      \n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", best_xgb)\n",
    "])\n",
    "\n",
    "# Cross-Validation auf Trainingsdaten \n",
    "cv_scores = cross_val_score(\n",
    "    pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"r2\"\n",
    ")\n",
    "\n",
    "print(\"CV R² Scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", cv_scores.mean())\n",
    "print(\"Std CV R²:\", cv_scores.std())\n",
    "\n",
    "# 2) Final Fit + Evaluation auf Testset\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Final Test R²: {r2:.4f}\")\n",
    "print(f\"Final Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Modell speichern\n",
    "with open(\"lol_pickrate_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = pipeline.named_steps[\"model\"]\n",
    "\n",
    "# Plotten\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Feature-Namen aus dem Preprocessor holen\n",
    "num_names = numeric_features\n",
    "cat_names = categorical_features\n",
    "\n",
    "feature_names = num_names + cat_names\n",
    "\n",
    "xgb_model = pipeline.named_steps[\"model\"]\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "for name, score in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Championgenerierung / Ergebnisinterpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wollen wir das beste Modell anwenden, um zu testen, ob es genau ist\n",
    "Daher nehmen wir die Werte eine Champions der Reihe 1 und testen, ob das Modell \n",
    "die Pickrate korrekt vorhersagt\n",
    "Dazu müssen wir die Werte nicht aus den Trainingsdaten nemhen, sondern aus den ursprünglichen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir bedienen uns der vor langer Zeit erstellten \"Backup\" - Variable df_name,\n",
    "# um die Spalte 'Name' wieder hinzuzufügen\n",
    "\n",
    "df_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die echten Werte des Champions \"Aatrox' anzeigen\n",
    "champion = df_name[df_name['Name'] == 'Aatrox'].iloc[0].to_dict()\n",
    "champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickrate vorhersagen\n",
    "with open(\"lol_pickrate_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte des Champions in ein DataFrame umwandeln\n",
    "champion_df = pd.DataFrame([champion])\n",
    "\n",
    "# Namensspalte rausnehmen\n",
    "champion_df = champion_df.drop(columns=[\"Name\"], errors=\"ignore\")\n",
    "                               \n",
    "# Pickrate vorhersagen\n",
    "pickrate = model.predict(champion_df)[0]\n",
    "print(f\"Vorhergesagte Pickrate für Aatrox: {pickrate:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte des Champions \"Xerath' betrachten\n",
    "champion = df_name[df_name['Name'] == 'Xerath'].iloc[0].to_dict()\n",
    "champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion = df_name[df_name['Name'] == 'Xerath'].iloc[0].to_dict()\n",
    "champion_df = pd.DataFrame([champion])\n",
    "champion_df = champion_df.drop(columns=[\"Name\"], errors=\"ignore\")\n",
    "pickrate = pipeline.predict(champion_df)[0]\n",
    "print(f\"Vorhergesagte Pickrate für Xerath: {pickrate:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Pickrates wurden super vorhergesagt! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Champion mit niedrigster Pickrate als Vergleich anzeigen\n",
    "champion_underrep = df_name.loc[df_name[\"Pick %\"].idxmin()]\n",
    "print(\"Champion mit den am niedrigsten Pickrate:\")\n",
    "print(champion_underrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt werden durchschnittliche Werte für alle Variablen außer Class und Role genommen, um diese kategorialen Variablen vorherzusagen. Es soll nämlich erkannt werden, welche Klasse und Rolle bei durchschnittlichen Werten am unterrepräsentiertesten ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell laden\n",
    "with open(\"lol_pickrate_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren kategorialer Features\n",
    "variable_features = ['Class', 'Role']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen aller möglichen Kombinationen aus Class und Role\n",
    "combinations = list(product(\n",
    "    df['Class'].dropna().unique(),\n",
    "    df['Role'].dropna().unique()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen aller anderen Features auf den Mittelwert\n",
    "fixed_values = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in variable_features + ['Name', 'Pick %']:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            fixed_values[col] = df[col].mean()\n",
    "        else:\n",
    "            fixed_values[col] = df[col].mode()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterieren durch alle Kombinationen der kategorialen Werte\n",
    "min_pred = float('inf')\n",
    "best_candidate = None\n",
    "\n",
    "for class_val, role_val in combinations:\n",
    "    candidate = fixed_values.copy()\n",
    "    candidate['Class'] = class_val\n",
    "    candidate['Role'] = role_val\n",
    "\n",
    "    candidate_df = pd.DataFrame([candidate])\n",
    "    pred = model.predict(candidate_df)[0]\n",
    "\n",
    "    if pred < min_pred:\n",
    "        min_pred = pred\n",
    "        best_candidate = candidate\n",
    "\n",
    "print(\"Theoretische Champion-Komposition (bei durchschnittlicher Leistung):\")\n",
    "print(best_candidate)\n",
    "print(\"Vorhergesagte Pickrate: {:.2f}%\".format(min_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisinterpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse zeigt, dass die Rolle \"Top\" und die Klasse \"Tank\" (Class Tank) bei durschnittlichen Werten unterrepräsentierte Champions ausmacht. Besonders die Klasse lässt sich logisch nachvollziehen, beispielsweise wurden Champions der Klasse \"Tank\", in den letzten Jahren oft gar nicht oder selten pro Jahr veröffentlicht. Weiters wird auf diese Thematik in der schriftlichen Arbeit genauer eingegangen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
